`r opts_chunk$set(tidy = FALSE)`
`r opts_chunk$set(fig.width = 8)`
`r opts_chunk$set(fig.height = 5)`
`r opts_chunk$set(cache = TRUE)`


# 90 Years of Harvard Business Review

I'm working on the Harvard Business Review data set (a [kaggle](http://www.kaggle.com/) [thing](https://www.kaggle.com/c/harvard-business-review-vision-statement-prospect/)). I want to make the timeline more physically intuitive and more closely linked to the pages of HBR. I'm using R with knitr (R markdown) and showing all my work, with some use of stopifnot() and commenting some things out.

```{r}
# set up graphics for later
suppressPackageStartupMessages(library(ggplot2))
theme_set(theme_bw())

# Read in the provided file, available at the kaggle site
# https://www.kaggle.com/c/harvard-business-review-vision-statement-prospect/data
hbr <- read.csv('HBR Citations_correct_abstracts.csv',
              strip.white=TRUE,
              as.is=TRUE)
# This was working fine for a while and then something went wrong somehow with
# some unicode characters or something, so I had to do this on the command line:
# LC_CTYPE=C tr -c -d "[:alnum:][:punct:][:space:]" \
# < 'HBR Citations_correct_abstracts.csv' > hbr.csv
# cp 'HBR Citations_correct_abstracts.csv' original.csv
# mv hbr.csv 'HBR Citations_correct_abstracts.csv'
# Your mileage may vary.

# make sure we've got the expected number of observations
# as checked against the Excel files that were originally provided
stopifnot(nrow(hbr)==12751)

# confirm that there's always at most one of
# ABSTRACT or AUTHOR.SUPPLIED.ABSTRACT
stopifnot(all(hbr$ABSTRACT=="" | hbr$AUTHOR.SUPPLIED.ABSTRACT==""))
# and put it in a more convenient place
hbr$abstract <- ifelse(hbr$ABSTRACT!="",hbr$ABSTRACT,hbr$AUTHOR.SUPPLIED.ABSTRACT)
# preserve information just in case
hbr$abstract_type <- ifelse(hbr$ABSTRACT!="","HBR",
                            ifelse(hbr$AUTHOR.SUPPLIED.ABSTRACT!="","author",
                                   "none"))

# fix up the dates
# without this you incorrectly get results like year 2068, etc...
# the substringing only works because all the dates are 8 character
stopifnot(all(nchar(hbr$SYSTEM..PUB.DATE)==8))
hbr$dm <- substr(hbr$SYSTEM..PUB.DATE,1,6)
hbr$y <- substr(hbr$SYSTEM..PUB.DATE,7,8)
hbr$dmY <- ifelse(as.numeric(hbr$y)>20,
                  paste(hbr$dm,"19",hbr$y,sep=""),
                  paste(hbr$dm,"20",hbr$y,sep=""))
hbr$date <- as.Date(hbr$dmY,format="%d-%b-%Y")
hbr$year <- as.numeric(substr(hbr$date,1,4))
```

The first issue seems to have been published `r min(as.character(hbr$date))`. Everyone seems to agree on the year, at least. The [HBR wikipedia page](http://en.wikipedia.org/wiki/Harvard_Business_Review) adds this interesting tidbit:
> Harvard Business Review began in 1922 as a magazine for Harvard Business School. Founded under the auspices of Dean Wallace Donham, HBR was meant to be more than just a typical school publication. "The paper [HBR] is intended to be the highest type of business journal that we can make it, and for use by the student and the business man. It is not a school paper," Donham wrote.

```{r}
# columns "VOLUME", "ISSUE", and "PUBLICATION.DATE", which has something like
# volume names, are all moderately interesting,
# but I'll be mostly concerned with publication dates as pulled out above

# How often is HBR published?
years <- sort(unique(hbr$year))
dpy <- data.frame("year"=years,
                  "peryear"=sapply(years,function(x) {
                    length(unique(hbr$date[hbr$year==x]))
                    }))
qplot(year, peryear, data=dpy, main="publication dates per year")
```

There's some fluctuation from special supplements and just irregularities, but broadly it was quartlerly, then bi-monthly, then close to monthly (10, 11, or 12 times per year). I'll pull out the years that start the second and third epochs.

```{r}
# start of bi-monthly epoch
head(dpy[dpy$peryear==6,],1)

# start of near-monthly epoch
head(dpy[dpy$peryear==11,],1)

# let's look at page counts and word counts
hbr$pagesN <- hbr$PAGE.COUNT
# maybe it would be better to use "START.PAGE" and "END.PAGE"
# I don't think it's worth checking into that
# Let's look at page counts through time
pty <- data.frame("year"=years,
                  "pagesthrough"=sapply(years,function(x) {
                    sum(hbr$pagesN[hbr$year<=x], na.rm=TRUE)
                    }))
ggplot(pty, aes(year, pagesthrough)) + geom_area() + opts(title="cumulative pages") + geom_vline(xintercept=c(1948,2001), colour=I("red")) + geom_text(x=1931,y=50000,label=paste(round(sum(hbr$pagesN[hbr$year<1948&hbr$year>1922],na.rm=TRUE)/(1948-1922)),"pages/year",sep="\n"), colour=I("blue"), family="mono") + scale_x_continuous(limits=c(1920,2020)) + geom_text(x=1973,y=50000,label=paste(round(sum(hbr$pagesN[hbr$year<2001&hbr$year>=1948],na.rm=TRUE)/(2001-1948)),"pages/year",sep="\n"), colour=I("blue"), family="mono") + geom_text(x=2012,y=50000,label=paste(round(sum(hbr$pagesN[hbr$year<2012&hbr$year>=2001],na.rm=TRUE)/(2012-2001)),"pages/year",sep="\n"), colour=I("blue"), family="mono")
```

It looks like the changes in publishing frequency were not offset by too much thinning of individual issues.

```{r}
# too much in one line
with(hbr, plot(sort(unique(date)),tapply(pagesN,date,sum,na.rm=TRUE)[order(names(tapply(pagesN,date,sum,na.rm=TRUE)))],xlim=as.Date(c("1920-01-01","2020-01-01")),xlab="year",ylab="pages",main="pages per publication date"))
with(hbr, plot(sort(unique(year)),tapply(pagesN,year,sum,na.rm=TRUE)[order(names(tapply(pagesN,year,sum,na.rm=TRUE)))],xlim=c(1920,2020),xlab="year",ylab="pages",main="pages per publication year"))
```

Well, it looks like there was some drop in issue thickness when HBR went to the near-monthly frequency in 2001. But doubling (or nearly so) the frequency gave the highest ever yearly page counts. Here's how to space out the year labels in the combined anthology of all HBR ever, which is how to space out my timeline weighted by HBR commentary.

```{r}
pty$mark <- c(0, pty$pagesthrough / max(pty$pagesthrough))[-(nrow(pty)+1)]
print(pty,row.names=FALSE)
```

I would like to get a total word count.

```{r}
hbr$wordsN <- hbr$FULL.TEXT.WORD.COUNT
```

There are `r nrow(hbr)` entries total. Of these, `r nrow(hbr[!is.na(hbr$pagesN),])` have a page count, but only `r nrow(hbr[!is.na(hbr$wordsN),])` have a word count. (They started counting in `r head(sort(unique(hbr$year[!is.na(hbr$wordsN)])),1)`.) All but `r nrow(hbr[is.na(hbr$pagesN) & !is.na(hbr$wordsN),])` of the entries with word counts have page counts. Based on those entries, there's an average of `r with(hbr[!is.na(hbr$PAGE.COUNT) & !is.na(hbr$FULL.TEXT.WORD.COUNT),], sum(FULL.TEXT.WORD.COUNT)/sum(PAGE.COUNT))` words per page. At least [some people online](http://www.writersservices.com/wps/p_word_count.htm) think that's reasonable.

> At one extreme you get large print books with 250 words on the page. Academic books might put 600 words on a page with works of reference squeezing in 1000 words.

So we can get some sort of estimate of the total words ever published, adding in the word counts for the `r nrow(hbr[is.na(hbr$pagesN)&!is.na(hbr$wordsN),])` entries with word count but no page count, and giving the `r nrow(hbr[is.na(hbr$pagesN)&is.na(hbr$wordsN),])` entries with neither page count nor word count the average word count per entry with both of `r with(hbr[!is.na(hbr$pagesN) & !is.na(hbr$wordsN),], sum(wordsN)/length(pagesN))`.

```{r}
# calculate an estimated total word count for the history of HBR
# (not very readable...)
with(hbr[!is.na(hbr$pagesN) & !is.na(hbr$wordsN),], 
     sum(wordsN)/sum(pagesN)) * 
       with(hbr[!is.na(hbr$pagesN),], sum(pagesN)) +
       with(hbr[is.na(hbr$pagesN)&!is.na(hbr$wordsN),], sum(wordsN)) +
       with(hbr[!is.na(hbr$pagesN) & !is.na(hbr$wordsN),], 
            sum(wordsN)/length(pagesN)) *
       nrow(hbr[is.na(hbr$pagesN)&is.na(hbr$wordsN),])
```

I'm prepared to call that forty million words. It might be possible to do better using the "DOCUMENT.TYPE" column, but perhaps not much better. (There are four "Image" entries; three of them have word counts, all four have page counts.) Anyway, `r nrow(hbr[!is.na(hbr$pagesN),])/nrow(hbr)` of entries have page counts, for a total of `r with(hbr[!is.na(hbr$pagesN),], sum(pagesN))` pages. I'll use page count as a estimate of quantity of content.

```{r}
# Let's get into the text analysis.
# There are too many columns that I don't care about separately.
# (there has GOT to be a better way to do this...)
hbr$naics <- ""
for (j in grep("DESC",names(hbr))) {
  hbr$naics <- paste(hbr$naics, hbr[[j]])
}
hbr$subjects <- ""
for (j in grep("TERM",names(hbr))) {
  hbr$subjects <- paste(hbr$subjects, hbr[[j]])
}
hbr$keywords <- ""
for (j in grep("KEYWORD",names(hbr))) {
  hbr$keywords <- paste(hbr$keywords, hbr[[j]])
}
hbr$affils <- ""
for (j in grep("AFFIL",names(hbr))) {
  hbr$affils <- paste(hbr$affils, hbr[[j]])
}
# not sure how/if I want to completely deal with names yet
# this just does most frequent authors
# and adds a count of authors per article thing
first_names <- c()
last_names <- c()
names <- c()
affils <- c()
hbr$authorsN <- 0
for (i in 1:20) {
  last <- paste("AUTHOR.",i,".LAST.NAME",sep="")
  last_names <- c(last_names, hbr[[last]])
  first <- paste("AUTHOR.",i,".FIRST.NAME",sep="")
  first_names <- c(first_names, hbr[[first]])
  affil <- paste("AUTHOR.",i,".AFFILIATION",sep="")
  affils <- c(affils, hbr[[affil]]) 
  # if there's anything, that's an author
  hbr$authorsN <- hbr$authorsN + ifelse(hbr[[last]]=="" &
                                        hbr[[first]]=="" &
                                        hbr[[affil]]=="",
                                        0,1)
}
names <- paste(first_names,last_names)
hbr$authorsN[hbr$authorsN==0] <- NA
# meet the most prolific HBR authors
#tail(sort(table(names)),20)

# This might be interesting...
# authors per article over time
# excuse the numeric dates
with(hbr, smoothScatter(date,authorsN,main="authors per article over time",ylim=c(0,20)))
with(hbr, tapply(authorsN,DOCUMENT.TYPE,mean,na.rm=TRUE))
with(hbr, plot(sort(unique(year)), tapply(authorsN,year,mean,na.rm=T)))
with(hbr[hbr$DOCUMENT.TYPE=="Article",], plot(sort(unique(year)), tapply(authorsN,year,mean,na.rm=T)))
with(hbr[hbr$DOCUMENT.TYPE=="Article",], plot(sort(unique(substr(year,1,3))), tapply(authorsN,substr(year,1,3),mean,na.rm=T)))
# look at more stuff about number authors
with(hbr, tapply(authorsN,DOCUMENT.TYPE,mean,na.rm=T))




# could be useful
Sys.setenv(NOAWT=TRUE)
library(tm)
data("crude")
crude[[1]]
stemDocument(crude[[1]])
# and these are all vectorized
temp <- removeNumbers(crude[[1]])
temp <- removePunctuation(temp)
temp <- tolower(temp)
temp <- gsub('\n',' ',temp)
stemDocument(temp)
```
